# Tqdm vÃ  Wandb Integration

## ðŸ“Š **Tá»•ng quan**

Dá»± Ã¡n Ä‘Ã£ Ä‘Æ°á»£c tÃ­ch há»£p vá»›i **tqdm** Ä‘á»ƒ theo dÃµi progress bar vÃ  **wandb** Ä‘á»ƒ logging metrics trong quÃ¡ trÃ¬nh training.

## ðŸš€ **CÃ i Ä‘áº·t**

### 1. CÃ i Ä‘áº·t dependencies
```bash
pip install -r requirements.txt
```

### 2. Setup wandb
```bash
# CÃ¡ch 1: Login qua CLI
wandb login

# CÃ¡ch 2: Set API key
export WANDB_API_KEY=your_api_key_here

# CÃ¡ch 3: Cháº¡y setup script
python setup_wandb.py
```

## ðŸ“ˆ **Tqdm Progress Bars**

### **Training Progress**
```
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [02:30<00:00, 3.00s/it, Loss=0.1234, Contrastive=0.0567, Reconstruction=0.0667]
```

### **Validation Progress**
```
Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:30<00:00, 3.00s/it, Loss=0.1456, Contrastive=0.0678, Reconstruction=0.0778]
```

### **Features**
- âœ… Real-time loss display
- âœ… Progress percentage
- âœ… Time estimation
- âœ… Speed (iterations/second)
- âœ… Color-coded progress bars

## ðŸ“Š **Wandb Logging**

### **Batch-level Metrics**
- `batch/total_loss`: Total loss per batch
- `batch/contrastive_loss`: Contrastive loss per batch
- `batch/reconstruction_loss`: Reconstruction loss per batch
- `batch/learning_rate`: Learning rate per batch

### **Epoch-level Metrics**
- `epoch/train_total_loss`: Average training loss per epoch
- `epoch/train_contrastive_loss`: Average contrastive loss per epoch
- `epoch/train_reconstruction_loss`: Average reconstruction loss per epoch
- `epoch/val_total_loss`: Average validation loss per epoch
- `epoch/val_contrastive_loss`: Average validation contrastive loss per epoch
- `epoch/val_reconstruction_loss`: Average validation reconstruction loss per epoch
- `epoch/learning_rate`: Learning rate per epoch
- `epoch/epoch`: Epoch number

### **Validation Metrics**
- `val_batch/total_loss`: Validation loss per batch
- `val_batch/contrastive_loss`: Validation contrastive loss per batch
- `val_batch/reconstruction_loss`: Validation reconstruction loss per batch

## ðŸŽ¯ **Sá»­ dá»¥ng**

### **1. Training vá»›i Wandb (Máº·c Ä‘á»‹nh)**
```bash
python src/model/main.py --dataset ecg --epochs 10 --use_wandb
```

### **2. Training khÃ´ng Wandb**
```bash
python src/model/main.py --dataset ecg --epochs 10 --no_wandb
```

### **3. Custom Wandb Settings**
```bash
python src/model/main.py \
    --dataset ecg \
    --epochs 10 \
    --use_wandb \
    --project_name "my-project" \
    --experiment_name "experiment-1"
```

### **4. Demo Scripts**
```bash
# Demo Ä‘áº§y Ä‘á»§ vá»›i wandb
python demo_tqdm_wandb.py

# Demo Ä‘Æ¡n giáº£n
python simple_wandb_demo.py

# Setup wandb
python setup_wandb.py
```

## ðŸ”§ **Configuration**

### **Wandb Arguments**
```python
# Trong main.py
parser.add_argument('--use_wandb', action='store_true', default=True)
parser.add_argument('--no_wandb', dest='use_wandb', action='store_false')
parser.add_argument('--project_name', type=str, default='contrastive-learning')
parser.add_argument('--experiment_name', type=str, default=None)
```

### **Trainer Arguments**
```python
# Trong ContrastiveTrainer
trainer = ContrastiveTrainer(
    model=model,
    train_dataloader=train_dataloader,
    val_dataloader=val_dataloader,
    use_wandb=True,  # Enable/disable wandb
    project_name='contrastive-learning',
    experiment_name='my-experiment'
)
```

## ðŸ“± **Wandb Dashboard**

### **Truy cáº­p Dashboard**
1. Äi tá»›i [https://wandb.ai](https://wandb.ai)
2. Login vÃ o tÃ i khoáº£n
3. Navigate Ä‘áº¿n project `contrastive-learning`
4. Xem run `my-experiment`

### **Metrics Visualization**
- **Loss Curves**: Training vÃ  validation loss theo thá»i gian
- **Learning Rate**: Learning rate schedule
- **Batch Metrics**: Real-time metrics per batch
- **System Metrics**: CPU, GPU usage (náº¿u cÃ³)

## ðŸŽ¨ **Customization**

### **ThÃªm Custom Metrics**
```python
# Trong train_epoch()
if self.use_wandb:
    wandb.log({
        'custom/my_metric': custom_value,
        'custom/another_metric': another_value
    })
```

### **Custom Progress Bar**
```python
# Trong train_epoch()
pbar = tqdm(self.train_dataloader, desc="Training", 
           bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]')
```

### **Custom Wandb Config**
```python
# Trong __init__
wandb.init(
    project=project_name,
    name=experiment_name,
    config={
        'custom_param': custom_value,
        'model_architecture': 'TCN+Transformer',
        'dataset': 'ECG'
    }
)
```

## ðŸ› **Troubleshooting**

### **Wandb Issues**
```bash
# Check wandb status
wandb status

# Login again
wandb login

# Check API key
echo $WANDB_API_KEY
```

### **Tqdm Issues**
```python
# Disable tqdm
from tqdm import tqdm
tqdm.disable = True

# Or use tqdm with different settings
pbar = tqdm(dataloader, disable=True)
```

### **Common Errors**
1. **Wandb not logged in**: Run `wandb login`
2. **API key invalid**: Check `WANDB_API_KEY` environment variable
3. **Project not found**: Create project on wandb dashboard
4. **Tqdm not showing**: Check if running in terminal (not IDE)

## ðŸ“š **Examples**

### **Basic Training**
```python
from src.model.train_contrastive import ContrastiveTrainer
from src.model.contrastive_model import ContrastiveModel

# Create model
model = ContrastiveModel(input_dim=2, d_model=64)

# Create trainer with wandb
trainer = ContrastiveTrainer(
    model=model,
    train_dataloader=train_dataloader,
    use_wandb=True,
    project_name='my-project'
)

# Train
history = trainer.train(num_epochs=10)
```

### **Custom Logging**
```python
# Log custom metrics
wandb.log({
    'custom/accuracy': accuracy,
    'custom/f1_score': f1_score,
    'custom/precision': precision,
    'custom/recall': recall
})
```

## ðŸŽ¯ **Best Practices**

1. **Wandb**:
   - Sá»­ dá»¥ng tÃªn experiment cÃ³ Ã½ nghÄ©a
   - Group cÃ¡c runs liÃªn quan
   - Log hyperparameters quan trá»ng
   - Sá»­ dá»¥ng tags Ä‘á»ƒ organize

2. **Tqdm**:
   - Sá»­ dá»¥ng desc Ä‘á»ƒ mÃ´ táº£ rÃµ rÃ ng
   - Customize postfix Ä‘á»ƒ hiá»ƒn thá»‹ metrics quan trá»ng
   - Sá»­ dá»¥ng unit Ä‘á»ƒ hiá»ƒn thá»‹ Ä‘Æ¡n vá»‹

3. **Logging**:
   - Log cáº£ batch-level vÃ  epoch-level metrics
   - Sá»­ dá»¥ng prefix Ä‘á»ƒ group metrics
   - Log learning rate vÃ  other hyperparameters

## ðŸ”— **Links**

- [Wandb Documentation](https://docs.wandb.ai/)
- [Tqdm Documentation](https://tqdm.github.io/)
- [Wandb Dashboard](https://wandb.ai)
- [Project Repository](#)

---

**Happy Training! ðŸš€**
